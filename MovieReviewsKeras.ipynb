{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MovieReviewsKeras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyN3OPDCdR61NGMtvIgG3B9l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SouvikakaPuka/Data-Science/blob/master/MovieReviewsKeras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnaOb3-XWQsV",
        "colab_type": "code",
        "outputId": "a6b4e965-a1d0-4a86-f385-5a2711d1d3f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "# Import the pandas library to read our dataset\n",
        "import pandas as pd\n",
        "from pandas import DataFrame, Series\n",
        "# Get the train/test split package from sklearn for preparing our dataset to\n",
        "# train and test the model with\n",
        "from sklearn.model_selection import train_test_split\n",
        "#For PCA\n",
        "from sklearn.decomposition import PCA, TruncatedSVD\n",
        "# Import the numpy library to work with and manipulate the data\n",
        "import numpy as np\n",
        "import nltk\n",
        "import random\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "# nltk.download('movie_reviews')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n69NkVqpWgUU",
        "colab_type": "code",
        "outputId": "306ef31f-be90-4a25-c642-bbc47876caab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Conv1D, Flatten, MaxPooling1D, GlobalAveragePooling1D, BatchNormalization, Dropout\n",
        "from keras.optimizers import SGD, Adam, Nadam, RMSprop, Adamax\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBDxVZa_WnSA",
        "colab_type": "code",
        "outputId": "4eaa7060-3414-4d32-f537-d134401e0359",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "dataset = pd.read_csv('https://raw.githubusercontent.com/cacoderquan/Sentiment-Analysis-on-the-Rotten-Tomatoes-movie-review-dataset/master/train.tsv', sep = '\\t')\n",
        "dataset.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...  Sentiment\n",
              "0         1  ...          1\n",
              "1         2  ...          2\n",
              "2         3  ...          2\n",
              "3         4  ...          2\n",
              "4         5  ...          2\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXgowz32WseT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X = dataset['Phrase']\n",
        "# Y = dataset['Sentiment']\n",
        "# print(X.shape, Y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ifw4kApKWwIg",
        "colab_type": "code",
        "outputId": "2b264912-5bb3-469f-fe6a-c8dd9b689678",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "ds = dataset.copy()\n",
        "ds = ds.drop(columns = ['PhraseId', 'SentenceId'])\n",
        "ds.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Phrase  Sentiment\n",
              "0  A series of escapades demonstrating the adage ...          1\n",
              "1  A series of escapades demonstrating the adage ...          2\n",
              "2                                           A series          2\n",
              "3                                                  A          2\n",
              "4                                             series          2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRBnQ6iJW0I1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "documents = ds.values.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0C_WxfVW4Kp",
        "colab_type": "code",
        "outputId": "7cba87c7-ad99-44ce-d9c3-9e4d84c53cff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer, LancasterStemmer\n",
        "porter = PorterStemmer()\n",
        "lancaster=LancasterStemmer()\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "stopwords_en = stopwords.words(\"english\")\n",
        "punctuations=\"?:!.,;'\\\"-()\"\n",
        "#parameters to adjust to see the impact on outcome\n",
        "remove_stopwords = True\n",
        "useStemming = False\n",
        "useLemma = True\n",
        "removePuncs = True\n",
        "\n",
        "for l in range(len(documents)): #For each review document\n",
        "  label = documents[l][1] #Save review label\n",
        "  tmpReview = [] #Placeholder list for new review\n",
        "  for w in documents[l][0].split(' '): #For each word this is review\n",
        "    newWord = w #Set newWork to be the updated word\n",
        "    if remove_stopwords and (w in stopwords_en):#if the word is a stopword & we want to remove stopwords\n",
        "      continue #skip the word and don’t had it to the normalized review\n",
        "    if removePuncs and (w in punctuations):#if the word is a punc. & we want to remove punctuations\n",
        "      continue #skip the word and don’t had it to the normalized review\n",
        "    if useStemming: #if useStemming is set to True\n",
        "      #Keep one stemmer commented out\n",
        "      #newWord = porter.stem(newWord) #User porter stemmer\n",
        "      newWord = lancaster.stem(newWord) #Use Lancaster stemmer\n",
        "    if useLemma:\n",
        "      newWord = wordnet_lemmatizer.lemmatize(newWord)\n",
        "    tmpReview.append(newWord) #Add normalized word to the tmp review\n",
        "  documents[l] = (' '.join(tmpReview), label) #Update the reviews list with clean review\n",
        "print(documents[1])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('A series escapade demonstrating adage good goose', 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ej3VFSXZ37-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_data = pd.DataFrame(documents,\n",
        "                                columns=['text', 'sentiment'])\n",
        "# Splits the dataset so 70% is used for training and 30% for testing\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(all_data['text'], all_data['sentiment'], test_size=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Z4QrhPd46K3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "#Initialize number of features to be considered\n",
        "vec_length = 2500\n",
        "# Transform each text into a vector of word counts\n",
        "# vectorizer = CountVectorizer(stop_words=\"english\",\n",
        "#                              ngram_range=(1, 1), max_features = vec_length)\n",
        "vectorizer = TfidfVectorizer(stop_words=\"english\",\n",
        "                            ngram_range=(1, 1), max_features = vec_length)\n",
        "#X = vectorizer.fit_transform(all_data[\"text\"])\n",
        "#Y = all_data['sentiment']\n",
        "x_train = vectorizer.fit_transform(X_train)\n",
        "y_train = Y_train\n",
        "x_test = vectorizer.transform(X_test)\n",
        "y_test = Y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mpxm_laXNbN",
        "colab_type": "code",
        "outputId": "b2d952d1-84df-4ffc-ce64-039d3c98c1b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "# Converts the datasets to numpy arrays to work with the model\n",
        "\n",
        "np.random.seed(9001)\n",
        "\n",
        "#Convert the training data\n",
        "# x_train_np = x_train\n",
        "x_train_np = x_train.toarray()\n",
        "y_train_np = to_categorical(y_train)\n",
        "# y_train_np = np.array(y_train)\n",
        "\n",
        "# Convert the testing data\n",
        "# x_test_np = x_test\n",
        "x_test_np = x_test.toarray()\n",
        "y_test_np = to_categorical(y_test)\n",
        "# y_test_np = np.array(y_test)\n",
        "\n",
        "print(x_train_np.shape)\n",
        "print(y_train_np.shape)\n",
        "print(x_test_np.shape)\n",
        "print(y_test_np.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(109242, 2500)\n",
            "(109242, 5)\n",
            "(46818, 2500)\n",
            "(46818, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cXvzPbKXZjy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Changing input variable distribution to format to feed the model\n",
        "\n",
        "x_train_np = np.expand_dims(x_train_np, axis=2)\n",
        "x_test_np = np.expand_dims(x_test_np, axis=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wO3oR-4Xf-g",
        "colab_type": "code",
        "outputId": "ce9fba99-64ba-4921-8414-5226551f97a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#create model\n",
        "\n",
        "model = Sequential()\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv1D(filters = 128, kernel_size=1, activation='relu', input_shape=(x_train_np.shape[1],1)))\n",
        "# model.add(MaxPooling1D(pool_size =2))\n",
        "model.add(Conv1D(filters = 128, kernel_size=1, activation='relu'))\n",
        "# model.add(MaxPooling1D(pool_size =2))\n",
        "# model.add(Conv1D(filters = 128, kernel_size=1, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size =2))\n",
        "# model.add(GlobalAveragePooling1D())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "# model.add(Dropout(0.5))\n",
        "# model.add(BatchNormalization())\n",
        "model.add(Dense(5, activation='softmax'))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2i7a6IdRLch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create metrics for Precision, Recall, and F-1 Score\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "def recall(y_true, y_pred):\n",
        "  true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "  possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "  recall = true_positives / (possible_positives + K.epsilon())\n",
        "  return recall\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "  true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "  predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "  precision = true_positives / (predicted_positives + K.epsilon())\n",
        "  return precision\n",
        "\n",
        "def f1score(y_true, y_pred):\n",
        "\n",
        "  prec = precision(y_true, y_pred)\n",
        "  rec = recall(y_true, y_pred)\n",
        "  f1score = (2 * (prec * rec)/(rec + prec))\n",
        "  return f1score\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPlaz_OGY689",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Optimizers\n",
        "adam = keras.optimizers.Adam(lr = 0.0001)\n",
        "sgd = keras.optimizers.SGD(lr = 0.0001)\n",
        "nadam = keras.optimizers.Nadam(lr = 0.0001)\n",
        "rms = keras.optimizers.RMSprop(lr = 0.0001)\n",
        "adamax = keras.optimizers.Adamax(lr = 0.0001)\n",
        "#Compiling the model\n",
        "model.compile(optimizer=adamax, loss='categorical_crossentropy', metrics=['accuracy', recall, precision, f1score])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8d7KYOPYV0w",
        "colab_type": "code",
        "outputId": "39512889-dbda-428d-eca2-a789b8f38041",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "batch_size = 128  # Batch size\n",
        "epochs = 10 # Number of eopchs\n",
        "\n",
        "#Training the model\n",
        "history = model.fit(x_train_np, y_train_np, validation_data=( x_test_np, y_test_np), epochs= epochs, batch_size = batch_size)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 109242 samples, validate on 46818 samples\n",
            "Epoch 1/10\n",
            "109242/109242 [==============================] - 123s 1ms/step - loss: 0.6280 - acc: 0.7498 - recall: 0.7224 - precision: 0.7710 - f1score: 0.7458 - val_loss: 1.2116 - val_acc: 0.6132 - val_recall: 0.5837 - val_precision: 0.6301 - val_f1score: 0.6059\n",
            "Epoch 2/10\n",
            "109242/109242 [==============================] - 123s 1ms/step - loss: 0.6216 - acc: 0.7512 - recall: 0.7243 - precision: 0.7725 - f1score: 0.7475 - val_loss: 1.2183 - val_acc: 0.6142 - val_recall: 0.5875 - val_precision: 0.6290 - val_f1score: 0.6074\n",
            "Epoch 3/10\n",
            "109242/109242 [==============================] - 122s 1ms/step - loss: 0.6193 - acc: 0.7513 - recall: 0.7243 - precision: 0.7727 - f1score: 0.7476 - val_loss: 1.2350 - val_acc: 0.6141 - val_recall: 0.5843 - val_precision: 0.6284 - val_f1score: 0.6055\n",
            "Epoch 4/10\n",
            "109242/109242 [==============================] - 121s 1ms/step - loss: 0.6177 - acc: 0.7520 - recall: 0.7253 - precision: 0.7727 - f1score: 0.7482 - val_loss: 1.2421 - val_acc: 0.6137 - val_recall: 0.5840 - val_precision: 0.6282 - val_f1score: 0.6052\n",
            "Epoch 5/10\n",
            "109242/109242 [==============================] - 122s 1ms/step - loss: 0.6159 - acc: 0.7524 - recall: 0.7259 - precision: 0.7736 - f1score: 0.7489 - val_loss: 1.2460 - val_acc: 0.6128 - val_recall: 0.5835 - val_precision: 0.6278 - val_f1score: 0.6047\n",
            "Epoch 6/10\n",
            "109242/109242 [==============================] - 122s 1ms/step - loss: 0.6143 - acc: 0.7530 - recall: 0.7267 - precision: 0.7735 - f1score: 0.7492 - val_loss: 1.2507 - val_acc: 0.6142 - val_recall: 0.5850 - val_precision: 0.6275 - val_f1score: 0.6054\n",
            "Epoch 7/10\n",
            "109242/109242 [==============================] - 121s 1ms/step - loss: 0.6128 - acc: 0.7533 - recall: 0.7273 - precision: 0.7742 - f1score: 0.7499 - val_loss: 1.2540 - val_acc: 0.6134 - val_recall: 0.5833 - val_precision: 0.6280 - val_f1score: 0.6047\n",
            "Epoch 8/10\n",
            "109242/109242 [==============================] - 123s 1ms/step - loss: 0.6114 - acc: 0.7530 - recall: 0.7267 - precision: 0.7742 - f1score: 0.7496 - val_loss: 1.2598 - val_acc: 0.6129 - val_recall: 0.5846 - val_precision: 0.6273 - val_f1score: 0.6051\n",
            "Epoch 9/10\n",
            "109242/109242 [==============================] - 121s 1ms/step - loss: 0.6099 - acc: 0.7533 - recall: 0.7264 - precision: 0.7743 - f1score: 0.7495 - val_loss: 1.2708 - val_acc: 0.6118 - val_recall: 0.5868 - val_precision: 0.6260 - val_f1score: 0.6057\n",
            "Epoch 10/10\n",
            "109242/109242 [==============================] - 121s 1ms/step - loss: 0.6090 - acc: 0.7538 - recall: 0.7283 - precision: 0.7752 - f1score: 0.7509 - val_loss: 1.2744 - val_acc: 0.6125 - val_recall: 0.5881 - val_precision: 0.6253 - val_f1score: 0.6061\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VZicV6CTvMF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "c422dae5-5704-4b4a-b43f-00e926356b4c"
      },
      "source": [
        "#Evaluating the model on training data\n",
        "\n",
        "train_loss, train_accuracy, train_recall, train_precision, train_f1score = model.evaluate(x_train_np, y_train_np)\n",
        "print(\"Train Loss: \", train_loss)\n",
        "print(\"Train Accuracy: \", train_accuracy)\n",
        "print(\"Train Recall: \", train_recall)\n",
        "print(\"Train Precision: \", train_precision)\n",
        "print(\"Train F1 Score: \", train_f1score)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "109242/109242 [==============================] - 48s 442us/step\n",
            "Train Loss:  0.5905579630968822\n",
            "Train Accuracy:  0.7626645429359034\n",
            "Train Recall:  0.7379487742765892\n",
            "Train Precision:  0.7825544319272257\n",
            "Train F1 Score:  0.7592325137338142\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3EupiH7Ubas",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "57553bd2-e86d-481d-d11b-56a081cea21e"
      },
      "source": [
        "#Evaluating the model on test data\n",
        "\n",
        "test_loss, test_accuracy, test_recall, test_precision, test_f1score = model.evaluate(x_test_np, y_test_np)\n",
        "print(\"Test Loss: \", test_loss)\n",
        "print(\"Test Accuracy: \", test_accuracy)\n",
        "print(\"Test Recall: \", test_recall)\n",
        "print(\"Test Precision: \", test_precision)\n",
        "print(\"Test F1 Score: \", test_f1score)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "46818/46818 [==============================] - 20s 430us/step\n",
            "Test Loss:  1.2744478743773686\n",
            "Test Accuracy:  0.6124994660173437\n",
            "Test Recall:  0.5881498568926481\n",
            "Test Precision:  0.6253334948648794\n",
            "Test F1 Score:  0.6058717137180739\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p63ophiCq8AL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('1116613_1dconv_classify.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}